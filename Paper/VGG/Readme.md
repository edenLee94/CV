## VGG!
VGG-11, 16,19 → 점차 depth가 깊어지면서, 성능이 좋아졌으며, 8-layer로 구성된 AlexNet(2012)보다 2배 이상 깊은 network다.
논문에서 제공한 표를 통해서 확인해보면, 모든 layer에서 커널 사이즈는 3x3, pooling size는 2x2를 사용했다.


실험 과정을 보면, 
- A(conv:11), A-LRN, B(conv:13),C(16),D(C에 비해 kernel의 크기 커짐),E(19) 5가지 모델에 대해 실험을 진행했다. 
- 그리고 신경망의 마지막 3개 Fully-Connected Layer는 각각 4096, 4096, 1000 개의 유닛으로 구성돼 있으며, 출력층(1000: class의 수)은 classification을 위한 Softmax 함수를 사용한다.

실험 결과로 
- 깊이가 깊어질수록 이미지 분류 정확도가 높아 성능이 좋아졌다.
- LRN은 성능에 큰 영향을 주지 않았다.(A vs A-LRN)
- AlexNet의 오차율을 절반(16.4 -> 7.3)으로 줄였다.

학교 강의에서 들었을 때, memory & parameter 수에 대한 내용에 대한 내용을 학습했는데, 각 과정에서 학습 parameter의 수를 계산했었다.
많이 사용되는 이유로 미리 정의된 것을 그냥 사용해도 된다.(아마도..?)
